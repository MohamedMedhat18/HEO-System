name: AI Auto-Update

on:
  schedule:
    # Run every Sunday at 00:00 UTC
    - cron: '0 0 * * 0'
  workflow_dispatch:  # Allow manual trigger

permissions:
  contents: write
  pull-requests: write

jobs:
  ai-analysis:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pylint pycodestyle pytest pytest-cov
      
      - name: Create logs directory
        run: mkdir -p logs
      
      - name: Run UI Agent
        id: ui-agent
        run: |
          python -c "
          from agents.ui_agent.agent import UIAgent
          import json
          
          agent = UIAgent()
          result = agent.run()
          
          print('UI Agent Analysis Complete')
          print(json.dumps(result, indent=2))
          
          # Save results
          with open('logs/ui_agent_result.json', 'w') as f:
              json.dump(result, f, indent=2)
          "
        continue-on-error: true
      
      - name: Run Logic Agent
        id: logic-agent
        run: |
          python -c "
          from agents.logic_agent.agent import LogicAgent
          import json
          
          agent = LogicAgent()
          result = agent.run()
          
          print('Logic Agent Analysis Complete')
          print(json.dumps(result, indent=2))
          
          # Save results
          with open('logs/logic_agent_result.json', 'w') as f:
              json.dump(result, f, indent=2)
          "
        continue-on-error: true
      
      - name: Run Documentation Agent
        id: docs-agent
        run: |
          python -c "
          from agents.docs_agent.agent import DocsAgent
          import json
          
          agent = DocsAgent()
          result = agent.run()
          
          print('Documentation Agent Analysis Complete')
          print(json.dumps(result, indent=2))
          
          # Save results
          with open('logs/docs_agent_result.json', 'w') as f:
              json.dump(result, f, indent=2)
          "
        continue-on-error: true
      
      - name: Run Test Agent
        id: test-agent
        run: |
          python -c "
          from agents.test_agent.agent import TestAgent
          import json
          
          agent = TestAgent()
          result = agent.run()
          
          print('Test Agent Analysis Complete')
          print(json.dumps(result, indent=2))
          
          # Save results
          with open('logs/test_agent_result.json', 'w') as f:
              json.dump(result, f, indent=2)
          "
        continue-on-error: true
      
      - name: Generate Analysis Report
        run: |
          python -c "
          import json
          import os
          from datetime import datetime
          
          report = {
              'timestamp': datetime.utcnow().isoformat(),
              'agents': {}
          }
          
          # Load all agent results
          for agent in ['ui_agent', 'logic_agent', 'docs_agent', 'test_agent']:
              result_file = f'logs/{agent}_result.json'
              if os.path.exists(result_file):
                  with open(result_file, 'r') as f:
                      report['agents'][agent] = json.load(f)
          
          # Generate summary
          summary = []
          summary.append('# AI Analysis Report\n')
          summary.append(f'**Generated:** {report[\"timestamp\"]}\n\n')
          
          for agent_name, agent_data in report['agents'].items():
              summary.append(f'## {agent_name.replace(\"_\", \" \").title()}\n')
              
              # Analysis summary
              if 'analysis' in agent_data:
                  analysis = agent_data['analysis']
                  summary.append('### Analysis Results\n')
                  
                  if 'recommendations' in analysis:
                      summary.append(f'- **Recommendations:** {len(analysis[\"recommendations\"])}\n')
                  
                  if 'total_files' in analysis:
                      summary.append(f'- **Files Analyzed:** {analysis[\"total_files\"]}\n')
                  
                  if 'total_tests' in analysis:
                      summary.append(f'- **Tests Found:** {analysis[\"total_tests\"]}\n')
              
              # Improvements summary
              if 'improvements' in agent_data:
                  improvements = agent_data['improvements']
                  summary.append('### Improvements\n')
                  
                  if 'actions_taken' in improvements:
                      summary.append(f'- **Actions Taken:** {len(improvements[\"actions_taken\"])}\n')
                  
                  if 'errors' in improvements and improvements['errors']:
                      summary.append(f'- **Errors:** {len(improvements[\"errors\"])}\n')
              
              summary.append('\n')
          
          # Write report
          with open('logs/analysis_report.md', 'w') as f:
              f.writelines(summary)
          
          # Also write JSON
          with open('logs/analysis_report.json', 'w') as f:
              json.dump(report, f, indent=2)
          
          print('Analysis report generated')
          print(''.join(summary))
          "
      
      - name: Commit analysis results
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git add logs/
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore: weekly AI agent analysis [skip ci]"
            git push
          fi
      
      - name: Create Issue for Critical Recommendations
        if: always()
        run: |
          python -c "
          import json
          import os
          
          # Check for critical recommendations
          critical_items = []
          
          for agent in ['ui_agent', 'logic_agent', 'docs_agent', 'test_agent']:
              result_file = f'logs/{agent}_result.json'
              if os.path.exists(result_file):
                  with open(result_file, 'r') as f:
                      data = json.load(f)
                      analysis = data.get('analysis', {})
                      
                      # Check for critical recommendations
                      if 'recommendations' in analysis:
                          for rec in analysis['recommendations']:
                              if rec.get('priority') == 'critical' or rec.get('type') == 'critical':
                                  critical_items.append({
                                      'agent': agent,
                                      'recommendation': rec
                                  })
                      
                      # Check for security issues
                      if 'security_checks' in analysis:
                          for sec in analysis['security_checks']:
                              if sec.get('severity') == 'critical':
                                  critical_items.append({
                                      'agent': agent,
                                      'security': sec
                                  })
          
          if critical_items:
              print(f'Found {len(critical_items)} critical items')
              # In a real scenario, you would create a GitHub issue here
              # For now, just log them
              for item in critical_items:
                  print(f'Critical: {item}')
          else:
              print('No critical items found')
          "
      
      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-analysis-results
          path: logs/
          retention-days: 90
